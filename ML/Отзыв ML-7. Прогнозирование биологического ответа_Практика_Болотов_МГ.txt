Добрый день!
Спасибо за хорошо проделанную исследовательскую работу!  
В этом модуле познакомились с оптимизацией гиперпараметров как с помощью базовых методов (GridSeachCV, RandomizedSearchCV из библиотеки sklearn), так и с помощью продвинутых методов байесовской оптимизации (фреймворки Hyperopt, Optuna). Научились настраивать и обучать модель с использованием результатов работы этих методов. Провели сравнение методов на практике.

Плюсы работы:
— У документа есть структура
— Добавили описание поставленной задачи
— Применили все методы оптимизации к обеим моделям
— Применили кросс-валидацию для метода Hyperopt
— Сделали промежуточные выводы и краткий итоговый вывод
— Добавили визуализацию в работу

Что можно улучшить и комментарии к работе:
1. RandomForestClassifier - Это модуль Случайного леса, а не Дерево решений.
2. Кросс-валидацию можно было использовать и для метода Optuna.
2. В итоговом выводе было бы здорово добавить таблицу результатов по всем экспериментам.
3. Для более показательного результата, метрику можно показывать числом с 4-мя знаками после запятой.
4. Интересно фиксировать и время работы каждого метода и его тоже добавить в итоговые таблицы результатов. Так как чаще всего важны не только качество, но и скорость работы.

Полезные материалы:
Про подбор гиперпараметров:
https://habr.com/ru/company/skillfactory/blog/528240/ 
https://academy.yandex.ru/handbook/ml/article/podbor-giperparametrov 
Почти во всех методах есть аргумент отвечающий за вывод информации на экран. Например, для GridSearchCV - verbose, для Optuna - https://optuna.readthedocs.io/en/stable/reference/generated/optuna.logging.set_verbosity.html  

P.S. Возможно будет интересно и полезно изучить работу одного из студентов:
https://github.com/Abricovich/Abricovich-sf_data_science/blob/master/project_5/Kaggle_Predicting%20a%20Biological%20Response.ipynb 


Если возникнут вопросы, можете обратиться в канал # м_04_ml_7 в Пачке, постараемся на всё ответить и разобраться с моментами, которые вызывают трудности.
Удачи в обучении!